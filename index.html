<!DOCTYPE html>
<html>
<head></head>
    
<body>
<h3>A. Create a video file from screen capture</h3>
<button type="button" id="run_video_screen_capture" onclick="run_video_screen_capture()" style="display:block">A. Run video screen capture</button>


<h3>B. Create an audio file from recorder</h3>
<button type="button" id="record_audio" onclick="record_audio()" style="display:block">B. Record audio</button>
<button type="button" id="stop_record_audio" style="display:block">B. Stop record audio</button>


<h3>C. Modify/Play an existing audio and/or video file from file (In progress)</h3>

<!-- Dropdown: select a video and/or audio modification -->
<label for="select_video_andor_audio_file">Select a video and/or audio modification:</label>
<select name="video_andor_audio" id="video_andor_audio" style="display:block">
  <option value="---">Select an option</option>
  <option value="Obtain a video frame at a specific time">Obtain a video frame at a specific time</option>
  <option value="Append two audio files">Append two audio files</option>
  <option value="Combine an audio and video file">Combine an audio and video file</option>
  <option value="Append two video files">Append two video files</option>
  <option value="Play an audio from file">Play an audio from file</option>
</select>

<!-- Select a video and/or audio -->
<label for="select_video" id="select_video" style="display:none">Select an video:</label>
<input type="file" id="upload_video_file0" accept="video/*" style="display:none">
<input type="file" id="upload_video_file1" accept="video/*" style="display:none">

<label for="select_audio" id="select_audio" style="display:none">Select an audio:</label>
<input type="file" id="upload_audio_file0" accept="video/*" style="display:none">
<input type="file" id="upload_audio_file1" accept="video/*" style="display:none">
	
<button type="button" id="modify_existing_audio_and_or_video_from_file" onclick="modify_existing_audio_and_or_video_from_file()" style="display:block">C. Run audio/video processing</button>

<!-- ---------------------------------------- -->
	
<div id="data_display" style="display:block; text-align: left; width: 600px;">
<div id="notification"></div>
<div id="error"></div>

<!-- ---------------------------------------- -->
	
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  
<script>

window.addEventListener('beforeunload', function() {
	window.location.href = window.location.href + '?nocache=' + new Date().getTime();

	document.getElementById("video_andor_audio").selectedIndex = 0;
	document.getElementById("upload_video_file0").value = "";
	document.getElementById("upload_video_file1").value = "";
	document.getElementById("upload_audio_file0").value = "";
	document.getElementById("upload_audio_file1").value = "";
});
	
// -------------------------------------------------

document.getElementById("video_andor_audio").addEventListener("change", processEvent_video_andor_audio, false);

async function processEvent_video_andor_audio(event) {

	// there is nothing in event that tells which drop down was selected
	// console.log('event: ', event);

	const element = document.getElementById("video_andor_audio");
	
	console.log('element.selectedIndex: ', element.selectedIndex);
	
	if (document.getElementById("video_andor_audio").selectedIndex == 1) {
    // Obtain a video frame at a specific time
		document.getElementById("select_video").style.display = 'block';
    document.getElementById("upload_video_file0").style.display = 'block';
    document.getElementById("upload_video_file1").style.display = 'none';
    document.getElementById("select_audio").style.display = 'none';
    document.getElementById("upload_audio_file0").style.display = 'none';
    document.getElementById("upload_audio_file1").style.display = 'none';
    
	} else if (document.getElementById("video_andor_audio").selectedIndex == 2) {
    // Append two audio files
		document.getElementById("select_video").style.display = 'none';
    document.getElementById("upload_video_file0").style.display = 'none';
    document.getElementById("upload_video_file1").style.display = 'none';
    document.getElementById("select_audio").style.display = 'block';
    document.getElementById("upload_audio_file0").style.display = 'block';
    document.getElementById("upload_audio_file1").style.display = 'block';

  } else if (document.getElementById("video_andor_audio").selectedIndex == 3) {
    // Combine an audio and video file
    document.getElementById("select_video").style.display = 'block';
    document.getElementById("upload_video_file0").style.display = 'block';
    document.getElementById("upload_video_file1").style.display = 'none';
    document.getElementById("select_audio").style.display = 'block';
    document.getElementById("upload_audio_file0").style.display = 'block';
    document.getElementById("upload_audio_file1").style.display = 'none';

  } else if (document.getElementById("video_andor_audio").selectedIndex == 4) {
    // Append two video files
    document.getElementById("select_video").style.display = 'block';
    document.getElementById("upload_video_file0").style.display = 'block';
    document.getElementById("upload_video_file1").style.display = 'block';
    document.getElementById("select_audio").style.display = 'none';
    document.getElementById("upload_audio_file0").style.display = 'none';
    document.getElementById("upload_audio_file1").style.display = 'none';
	} else if (document.getElementById("video_andor_audio").selectedIndex == 5) {
    // Play an audio from file
    document.getElementById("select_video").style.display = 'none';
    document.getElementById("upload_video_file0").style.display = 'none';
    document.getElementById("upload_video_file1").style.display = 'none';
    document.getElementById("select_audio").style.display = 'block';
    document.getElementById("upload_audio_file0").style.display = 'block';
    document.getElementById("upload_audio_file1").style.display = 'none';
	}
	
}




  

  
// -------------------------------------------------
// A. Create a video file from screen capture
// -------------------------------------------------
async function run_video_screen_capture() {
    
    const displayMediaOptions = { video: { displaySurface: "browser", },
                                 audio: true,
                                 preferCurrentTab: true,
                                 selfBrowserSurface: "include",
                                 systemAudio: "include",
                                 surfaceSwitching: "include",
                                 monitorTypeSurfaces: "include",
                                };
    
    await navigator.mediaDevices.getDisplayMedia(displayMediaOptions)
        .then(stream => {  
		
		// This specifies the type of blob it will create for event.data
		// var options = {mimeType: "video/webm;codecs=vp8,opus"}; // save popup does not appear
		var options = {mimeType: "video/webm; audio/webm; codecs=vp8"};
		
		var mediaRecorder = new MediaRecorder(stream, options);

		// https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder/dataavailable_event
		// dataavailable runs when the MediaRecorder delivers media data to your application for its use
		// When mediaRecorder.stop() is called mediaRecorder.ondataavailable is run.
		// mediaRecorder.stop() is on the interface for the user to push.
		mediaRecorder.ondataavailable = handleDataAvailable;
		
		mediaRecorder.start();
        });

}

// -------------------------------------------------
    
function handleDataAvailable(event) {
	if (event.data.size > 0) {
		// event.data = Blob { size: 105571, type: "XXX" }
		console.log('event.data: ', event.data);
		
		download_screen_recording_video(event.data);
	}
}

// -------------------------------------------------
  
function download_screen_recording_video(blob_object) {

	console.log('blob_object: ', blob_object);
	
	var url = URL.createObjectURL(blob_object);
	var a = document.createElement("a");
	document.body.appendChild(a);
	a.setAttribute('style', 'display:none');
	a.setAttribute('href', url);
	a.setAttribute('download', 'test.webm');
      
	a.click();
  
	window.URL.revokeObjectURL(url);
}
	
// -------------------------------------------------



	


// -------------------------------------------------
// B. Create an audio file from recorder
// -------------------------------------------------
async function record_audio() {

	// https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder
	const MediaOptions = { audio: true };
  
    await navigator.mediaDevices.getUserMedia(MediaOptions)
        .then((stream) => {
		
		// This specifies the type of blob it will create for event.data
		var options = {mimeType: "audio/webm"};
		var mediaRecorder = new MediaRecorder(stream, options);
            
		mediaRecorder.start();
		console.log("recorder started - mediaRecorder.state: ", mediaRecorder.state);
		document.getElementById("record_audio").style.background = "red";
		document.getElementById("record_audio").style.color = "black";

		// Way 0
		document.getElementById("stop_record_audio").onclick = () => {
			mediaRecorder.stop();
			console.log("recorder stopped - mediaRecorder.state: ", mediaRecorder.state);
			document.getElementById("record_audio").style.background = "";
			document.getElementById("record_audio").style.color = "";
		};

		// When mediaRecorder.stop() is called mediaRecorder.ondataavailable is run.
		// mediaRecorder.stop() is called when the eventlistener is called for pushing the button stop_record_audio 
		mediaRecorder.ondataavailable = handleDataAvailable_audio;
		
            
      })
      .catch((err) => { console.error(`The following error occurred: ${err}`); });

}

// -------------------------------------------------

function handleDataAvailable_audio(event) {

	console.log('event: ', event);

	// If the recorded audio has size greater than zero, save it in an array
	if (event.data.size > 0) {
		// event.data = Blob { size: 38931, type: "XXX" }
		var url = URL.createObjectURL(event.data);
		console.log('url: ', url);
	}
	document.getElementById("stop_record_audio").removeEventListener("click", handleDataAvailable_audio);

	download_audio_recording(url);
}

// -------------------------------------------------

function download_audio_recording(url) {
	
	var a = document.createElement("a");
	document.body.appendChild(a);
	a.setAttribute('style', 'display:none');
	a.setAttribute('href', url);
	a.setAttribute('download', 'test.mp3');
      
	a.click();
  
	URL.revokeObjectURL(url);
}

// -------------------------------------------------



	


// -------------------------------------------------
// C. Modify an existing audio and/or video file from file
// -------------------------------------------------
async function modify_existing_audio_and_or_video_from_file() {
	
	// --------------------------
  
	var modification_type = document.getElementById("video_andor_audio").value;

	// --------------------------
	
	if (modification_type == 'Obtain a video frame at a specific time') {
		
		// Video to image
		const url_video0 = await fetch_file(base64_string_video0, file_name_video0, "video/webm");
		console.log('url_video0: ', url_video0);
    
		const videoElement = await load_video_from_url(url_video0, mode="nocors");
    
		await transform_video_to_image(videoElement);
		
	} else if (modification_type == 'Append two audio files') {
		
		const url_audio0 = await fetch_file(base64_string_audio0, file_name_audio0, "video/webm");
		console.log('url_audio0: ', url_audio0);
		const audioElement0 = await load_audio_from_url(url_audio0, mode="nocors");

		const url_audio1 = await fetch_file(base64_string_audio1, file_name_audio1, "video/webm");
		console.log('url_audio1: ', url_audio1);
		const audioElement1 = await load_audio_from_url(url_audio1, mode="nocors");
    
		var appended_normalArray_normalized = await append_two_audio_tracks(base64_string_audio0, base64_string_audio1);

		// I know how to play an audio from: 
		// 0) file (base64string, fetch on the base64string to get a blob object, Make a url for the blob object. Give url to audioElement.src.), 
		// 1) url (give url to audioElement.src), 
		// 2) blob_object via event mediastream (get event.data, which is a blob object. Make a url for the blob object. Give url to audioElement.src.). Sometimes blob_objects fail due to security issues.
		
		// Download the audio array and then play it
		var download_url = URL.createObjectURL(blob_object);
		await download_audio_recording(download_url);

		// is it possible to create a URL for an array, such that the url can be used to download tha array as an mp3 file? please give an example No, it is not possible to create a URL for an array that can be used to download it as an mp3 file.
		
	} else if (modification_type == 'Combine an audio and video file') {

		const url_audio0 = await fetch_file(base64_string_audio0, file_name_audio0, "video/webm");
		console.log('url_audio0: ', url_audio0);
		const audioElement = await load_audio_from_url(url_audio0, mode="nocors");

		const url_video0 = await fetch_file(base64_string_video0, file_name_video0, "video/webm");
		console.log('url_video0: ', url_video0);
		const videoElement = await load_video_from_url(url_video0, mode="nocors");
    
		await combine_audio_video(videoElement, audioElement);

	} else if (modification_type == 'Append two video files') {

		const url_video0 = await fetch_file(base64_string_video0, file_name_video0, "video/webm");
		console.log('url_video0: ', url_video0);
		const videoElement0 = await load_video_from_url(url_video0, mode="nocors");

		const url_video1 = await fetch_file(base64_string_video1, file_name_video1, "video/webm");
		console.log('url_video1: ', url_video1);
		const videoElement1 = await load_video_from_url(url_video1, mode="nocors");

		// Can stream a video to an empty video source

	} else if (modification_type == 'Play an audio from file') {
		
		const url_audio0 = await fetch_file(base64_string_audio0, file_name_audio0, "audio/mp3");
		console.log('url_audio0: ', url_audio0);
		const audioElement0 = await load_audio_from_url(url_audio0, mode="nocors");
		
	} else {
		document.getElementById('notification').innerHTML = "Please select an audio and/or video modification type."; 
	}

}







	
// -------------------------------------------------
// Basic functions to manipulate audio and video data
// -------------------------------------------------

// -------------------------------------------------
// 0. Obtain video frames: transform video to images
// -------------------------------------------------
async function transform_video_to_image(videoElement) {

	// Print video frame on a canvas
	var w = 224;
	const ctx = await create_dynamic_canvasElement(w);
	
	// This should plot the video frame on the canvas
	ctx.drawImage(videoElement, 0, 0, w, w);

	// Get the image data plotted on the canvas
	var imageData_OR_videoframe = ctx.getImageData(0, 0, w, w);
	// console.log('imageData_OR_videoframe: ', imageData_OR_videoframe);

	// -----------------------------------------------
	
	// Create a 4D array from the imageData_OR_videoframe
	// The oneD_array is interleaved with 4 components at each spatial data point (red, green, blue, alpha)
	var oneD_array = imageData_OR_videoframe.data; // data is a 1D array
	console.log('oneD_array: ', oneD_array);
	
	var red = [];
	var green = []; 
	var blue = [];
	var alpha = [];
	for (var i=0; i<len; i++) {
		red.push(oneD_array[i*4+0]); 		// Red component
		green.push(oneD_array[i*4+1]);	// Green component
		blue.push(oneD_array[i*4+2]);		// Blue component
		alpha.push(oneD_array[i*4+3]);	// Alpha component
	}
	
	// JavaScript 
	// shape (r, g, b, alpha)
	const fourD_array_javascript = await convert_four_1Darrays_to_one_4Darr(red, green, blue, alpha);
	console.log('fourD_array_javascript: ', fourD_array_javascript);
	
	// Tensorflow.js
	// the output shape of the matrix has 1 batch, 4 width, 4 height and 4 depth
	const data = [red, green, blue, alpha];
	const fourD_array_tensorflowjs = tf.tensor4d(data, [1, 4, 4, 4]);
	console.log('fourD_array_tensorflowjs: ', fourD_array_tensorflowjs);
	
	// -----------------------------------------------
	
	// Print modified video frame on a canvas
	const ctx_mod = await create_dynamic_canvasElement(w);

	// Manipulate image data, change the alpha component
	// Way 0: use the 4D data array
	let imageDataArray = new Uint8ClampedArray(28 * 28 * 4);
	for (let i = 0; i < 28 * 28; i++) {
	     let value = fourD_array_tensorflowjs.dataSync()[i];
	     imageDataArray[i * 4] = value > 0.5 ? 255 : 0; // Red component
	     imageDataArray[i * 4 + 1] = value > 0.5 ? 255 : 0; // Green component
	     imageDataArray[i * 4 + 2] = value > 0.5 ? 255 : 0; // Blue component
	     imageDataArray[i * 4 + 3] = 255; // Alpha component, set to 255 to make it fully opaque
	}

	// Print the manipulated image data on another canvas
	let imageData = new ImageData(imageDataArray, 28, 28);
	
	// Draw the image data onto the canvas
	ctx_mod.putImageData(imageData, 0, 0);

	// OR
	
	// Way 1: take the image directly from canvas ctx
	var len = imageData_OR_videoframe.data.length/4;
	for (var i=0; i<len; i++) {
		var r = imageData_OR_videoframe.data[i*4+0];	// Red component
		var g = imageData_OR_videoframe.data[i*4+1];	// Green component
		var b = imageData_OR_videoframe.data[i*4+2];	// Blue component
		// Alpha component, set to 0 to make it not opaque
		if (r<10 && g<10 && b<10){
			imageData_OR_videoframe.data[i*4+3] = 0;
		}
	}
	
	// Draw the image data onto the canvas
	ctx_mod.putImageData(imageData_OR_videoframe, 0, 0);

}

// -------------------------------------------------
	
async function convert_four_1Darrays_to_one_4Darr(arr0, arr1, arr2, arr3) {
	const cut_val = arr0.length/4;
	const stop_index = Array.from({ length: arr0.length }, (_, i) => (i+1)*cut_val);
	return javascript_4D_arr = [[
		[stop_index.map((val, ind) => { return arr0.slice(val-cut_val, val) })],
				    [stop_index.map((val, ind) => { return arr1.slice(val-cut_val, val) })],
				    [stop_index.map((val, ind) => { return arr2.slice(val-cut_val, val) })],
				    [stop_index.map((val, ind) => { return arr3.slice(val-cut_val, val) })]
	]];
}
	

// -------------------------------------------------
// 1. Append two Audio Tracks
// -------------------------------------------------
async function append_two_audio_tracks(binaryString_audio0, binaryString_audio1) {
	
	// -----------------------------------------------
	
	// Determine if the binaryString has mono or stero channels
	const audio_information0 = await obtain_audio_information_way0(binaryString_audio0);
	// audio_information0 = {channels: channels, time_length: time_length, fs: fs, time_sample_rate_OR_timePeriod: time_sample_rate_OR_timePeriod};
	// OR
	// Option 1: maybe look in https://www.npmjs.com/package/music-metadata#trackinfoaudiotrack

	const audio_information1 = await obtain_audio_information_way0(binaryString_audio1);
	
	// -----------------------------------------------

	const normalArray_normalized0 = await decodeAudioData_from_binaryString_to_uint8Array(binaryString_audio0);

	const normalArray_normalized1 = await decodeAudioData_from_binaryString_to_uint8Array(binaryString_audio1);

	// -----------------------------------------------
	
	if (audio_information0.channels == 2) {
		var audio0_channels = await separate_stero_channels(normalArray_normalized0);
	} else {
		// Mono channel
		var audio0_channels = [normalArray_normalized0];
	}

	if (audio_information1.channels == 2) {
		var audio1_channels = await separate_stero_channels(normalArray_normalized1);
	} else {
		// Mono channel
		var audio1_channels = [normalArray_normalized1];
	}
	
	// -----------------------------------------------
	
	// 4 cases
	var normalArray_normalized = [];
	console.log('audio0_channels.length: ', audio0_channels.length);
	console.log('audio1_channels.length: ', audio1_channels.length);
	
	if (audio0_channels.length == 2 && audio1_channels.length == 2) {
		// Both stero
		const audio0 = [audio0_channels.at(0), audio0_channels.at(1)];
		const audio1 = [audio1_channels.at(0), audio1_channels.at(1)];
		
		// const channel1_combined = audio0_channels.at(0).concat(audio1_channels.at(0));
		// const channel2_combined = audio0_channels.at(1).concat(audio1_channels.at(1));
		normalArray_normalized = await monoORstero_channels_to_singleArray(audio0, audio1);
		
	} else if (audio0_channels.length == 2 && audio1_channels.length == 1) {
		const audio0 = [audio0_channels.at(0), audio0_channels.at(1)];
		const audio1 = [audio1_channels.at(0),audio1_channels.at(0)];
		normalArray_normalized = await monoORstero_channels_to_singleArray(audio0, audio1);

	} else if (audio0_channels.length == 1 && audio1_channels.length == 2) {
		const audio0 = [audio0_channels.at(0), audio0_channels.at(0)];
		const audio1 = [audio1_channels.at(0),audio1_channels.at(1)];
		normalArray_normalized = await monoORstero_channels_to_singleArray(audio0, audio1);

	} else if (audio0_channels.length == 1 && audio1_channels.length == 1) {
		// Both are mono
		normalArray_normalized = audio0_channels.at(0).concat(audio1_channels.at(0));
	}

  return normalArray_normalized;
}

// -------------------------------------------------
	
async function monoORstero_channels_to_singleArray(audio0, audio1) {
	
	const channel1_combined = audio0.at(0).concat(audio1.at(0));
	const channel2_combined = audio0.at(1).concat(audio1.at(1));

	// Interweave the channels to reconstruct the audio
	const normalArray_normalized = [];
	var c = 0;
	for (var i=0; i<(channel1_combined.length+channel2_combined.length); i++) {
		if (i % 2 == 0) {
			normalArray_normalized.push(channel1_combined.at(c));
		} else {
			normalArray_normalized.push(channel2_combined.at(c));
		}
		c = c + 1;
	}
	return normalArray_normalized;
}

// -------------------------------------------------

async function obtain_audio_information_way0(binaryString_audio0) {

	var url_file_blob_object = await fetch(binaryString_audio0)
		.then(response => response.blob())
		.then(async function(blob_object) {
			return URL.createObjectURL(blob_object);
	});
	
	// -----------------------------------------------
	
	var audioElement = await load_audio_from_url(url_file_blob_object, mode="nocors");
	
	// -----------------------------------------------
 
	return await evaluate_audioElement();
}

// -------------------------------------------------

	
// -------------------------------------------------



// -------------------------------------------------
// 2. Combine a Video and Audio Track
// -------------------------------------------------
async function combine_audio_video(videoElement, audioElement) {
	
	const stream = new MediaStream();

	console.log('browser check: ', (/firefox/i).test(navigator.userAgent));
	
	if ((/firefox/i).test(navigator.userAgent) == true) {
		// Test - worked
		const captureStream_videoElement = videoElement.mozCaptureStream();
		console.log('captureStream_videoElement: ', captureStream_videoElement);

		// var video_id = captureStream_videoElement.id.slice(1, captureStream_videoElement.id.length-1);
		var video_id = captureStream_videoElement.id;
		console.log('video_id: ', video_id);

		const captureStream_audioElement = audioElement.mozCaptureStream();
		console.log('captureStream_audioElement: ', captureStream_audioElement);

		// var audio_id = captureStream_audioElement.id.slice(1, captureStream_videoElement.id.length-1);
		var audio_id = captureStream_audioElement.id;
		console.log('audio_id: ', audio_id);

		// -------------------------------------
		
		const captureStream_videoElement_tracks = captureStream_videoElement.getTrackById(video_id);
		console.log('captureStream_videoElement_tracks: ', captureStream_videoElement_tracks);

		const captureStream_audioElement_tracks = captureStream_audioElement.getTrackById(audio_id);
		console.log('captureStream_audioElement_tracks: ', captureStream_audioElement_tracks);

		// stream.addTrack(videoElement.mozCaptureStream().getVideoTracks()[0]);
		// stream.addTrack(audioElement.mozCaptureStream().getAudioTracks()[0]);
	} else {
		// const captureStream = videoElement.captureStream();
		//
		stream.addTrack(videoElement.captureStream().getVideoTracks()[0]);
		stream.addTrack(audioElement.captureStream().getAudioTracks()[0]);
	}
	

  
}
  
// -------------------------------------------------



// -------------------------------------------------
// 3. Append two Video Tracks
// -------------------------------------------------




// -------------------------------------------------
// DATA LOADING SUBFUNCTIONS
// -------------------------------------------------
async function fetch_file(base64_string, file_name, file_type) {

	// console.log('base64_string: ', base64_string.slice(0,20));
	
	return await fetch(base64_string)
		.then(response => response.blob())
		.then(async function(blob_object) {
			// console.log('blob_object: ', blob_object);
			return new File ([blob_object], file_name, {type: file_type});
		})
		.then(async function(file_blob_object) {
			// console.log('file_blob_object: ', file_blob_object);
			return URL.createObjectURL(file_blob_object);
		})
		.catch(error => { document.getElementById('error').innerHTML = error; });
}

// -------------------------------------------------



  


// -------------------------------------------------
// IMAGE SUBFUNCTIONS
// -------------------------------------------------
async function create_dynamic_canvasElement(w) {

  	const index = 0;
  
	// Create a canvas element
	var canvasElement = document.createElement('canvas');

	// Set the width and height of the canvas
	canvasElement.width = w;
	canvasElement.height = canvasElement.width;
	      
	// Get the 2D rendering context of the canvas
	var ctx = canvasElement.getContext("2d");
	
	if (index == 0) {
		canvasElement.style.left = 40+'px';
	} else {
		let tot = index*canvasElement.width + 40;
		canvasElement.style.left = tot+'px';
	}
	
	// Add the canvas to the document body or any other desired element
	document.getElementById('data_display').appendChild(canvasElement);

	return ctx;
}

// -------------------------------------------------

async function cropImage(img) {
	
	// Crop an image tensor to obtain a square image with no white space
	
	const size = Math.min(img.shape[0], img.shape[1]);
	const centerHeight = img.shape[0] / 2;
	const beginHeight = centerHeight - (size / 2);
	const centerWidth = img.shape[1] / 2;
	const beginWidth = centerWidth - (size / 2);
	return img.slice([beginHeight, beginWidth, 0], [size, size, 3]);
}

// -------------------------------------------------

	


// -------------------------------------------------
// AUDIO SUBFUNCTIONS
// -------------------------------------------------
async function play_sound_from_a_blob_object(blob_object, file_type) {

	// ie: file_type = "audio/mp3"
	
	// Putting an array, or mediastream event.data in a blob resulted in a Security Error
	var file_blob_object = new File ([blob_object], 'recorded_audio', {type: file_type});
	var url_file_blob_object = URL.createObjectURL(file_blob_object);
	
	await load_audio_from_url(url_file_blob_object, mode="nocors");
	
	URL.revokeObjectURL(url_file_blob_object);
  
}

// -------------------------------------------------

async function load_audio_from_url(url, mode="nocors") {

	// Create an AudioElement
	const audioElement = document.createElement('audio');
	
	audioElement.src = url;
	audioElement.id = "audio track";
	audioElement.autoplay = true;
	audioElement.setAttribute("controls", true);
	audioElement.setAttribute('preload', "auto");

	if (mode == "cors") {
		audioElement.setAttribute('crossOrigin', "anonymous");
	}

  	// Create an SourceElement (audioSourceNode)
	// var sourceElement = document.createElement('source');
	// sourceElement.setAttribute("src", url);
	// console.log('sourceElement: ', sourceElement);
  
	// audioElement.appendChild(sourceElement);
	
	document.getElementById('data_display').appendChild(audioElement);
	audioElement.onend = function() { URL.revokeObjectURL(url); }

	return audioElement;
}
	
// -------------------------------------------------

async function evaluate_audioElement() {

	// It appears that if the audioElement is in memory, these functions can be used

	// -----------------------------------------------
	
	// Create an AudioContext
	// var audioContext = new (window.AudioContext || window.webkitAudioContext)();
	// audioContext = new AudioContext();
	// OR
	var audioContext = new AudioContext();
 
	// -----------------------------------------------

	// Create an AnalyserNode: some signal information was more reliable with analyserNode than audioContext
	var analyserNode = audioContext.createAnalyser();
	// console.log('analyserNode: ', analyserNode);
	
	var channels = audioContext.channelCount;
	if (channels == undefined) { 
		channels = analyserNode.channelCount;
	}
	// console.log('channels: ', channels);
	
	var fs = audioContext.sampleRate;
	if (fs == undefined) { 
		fs = analyserNode.context.sampleRate; // 48000
	}
	// console.log('fs: ', fs);

	let time_length = analyserNode.context.currentTime;   // 354.976
	// console.log('time_length: ', time_length);

	// -----------------------------------------------

	const frameCount = fs * 2.0;
	
	var time_sample_rate_OR_timePeriod = (1/fs) * 1000; // every time_sample_rate there is a data point, 0.020833333333333333
	// console.log('time_sample_rate_OR_timePeriod: ', time_sample_rate_OR_timePeriod);

	// -----------------------------------------------
	
	return {channels: channels, fs: fs, time_length: time_length, frameCount: frameCount, time_sample_rate_OR_timePeriod: time_sample_rate_OR_timePeriod};
}

// -------------------------------------------------
	
// The eventlistener needs to be always running, to detect which file the user selected with browse
document.getElementById("upload_audio_file0").addEventListener("change", previewInput_audio0, false);
var file_name_audio0;
var base64_string_audio0;
	
async function previewInput_audio0(event) {

  // first file in the list of selected files, better for selecting multiple files at one time
	const file_audio = event.target.files[0];

	file_name_audio0 = file_audio.name;
	const reader_audio = new FileReader();
	reader_audio.onload = async function(e){ base64_string_audio0 = e.target.result; }
	reader_audio.readAsDataURL(file_audio);
}

// -------------------------------------------------

document.getElementById("upload_audio_file1").addEventListener("change", previewInput_audio1, false);
var file_name_audio1;
var base64_string_audio1;
	
async function previewInput_audio1(event) {

  // first file in the list of selected files, better for selecting multiple files at one time
	const file_audio = event.target.files[0];

	file_name_audio1 = file_audio.name;
	const reader_audio = new FileReader();
	reader_audio.onload = async function(e){ base64_string_audio1 = e.target.result; }
	reader_audio.readAsDataURL(file_audio);
}

// -------------------------------------------------

	

	


// -------------------------------------------------
// VIDEO SUBFUNCTIONS
// -------------------------------------------------
async function load_video_from_url(url, mode="nocors") {

  // Create an VideoElement
	const videoElement = document.createElement('video');
  
	videoElement.src = url;
	videoElement.id = "video track";
	videoElement.autoplay = true;
	videoElement.setAttribute("controls", true);
	videoElement.setAttribute('preload', "auto");

  if (mode == "cors") {
		videoElement.setAttribute('crossOrigin', "anonymous");
	}
	
	// console.log('videoElement: ', videoElement);
	
	document.getElementById('data_display').appendChild(videoElement);

  videoElement.onend = function() { URL.revokeObjectURL(url); }
	
	return videoElement;
}

// -------------------------------------------------
	
document.getElementById("upload_video_file0").addEventListener("change", previewInput_video0, false);
var file_name_video0;
var base64_string_video0;
	
async function previewInput_video0(event) {
	
	const file_video = event.target.files[0];  // first file in the list of selected files, better for selecting multiple files at one time
	// console.log("file_video :", file_video);
  
	// Set the file name
	file_name_video0 = file_video.name;
  
	const reader_video = new FileReader();
	reader_video.onload = async function(e){ base64_string_video0 = e.target.result; }
	reader_video.readAsDataURL(file_video);
}

// -------------------------------------------------

document.getElementById("upload_video_file1").addEventListener("change", previewInput_video1, false);

var file_name_video1;
var base64_string_video1;

async function previewInput_video1(event) {
	
	const file_video = event.target.files[0];  // first file in the list of selected files, better for selecting multiple files at one time
	// console.log("file_video :", file_video);
  
	// Set the file name
	file_name_video1 = file_video.name;
  
	const reader_video = new FileReader();
	reader_video.onload = async function(e){ base64_string_video1 = e.target.result; }
	reader_video.readAsDataURL(file_video);
}

// -------------------------------------------------

	
// -------------------------------------------------




  

	
// -------------------------------------------------
// AUDIO PRE-PROCESSING SUBFUNCTIONS
// -------------------------------------------------
async function separate_stero_channels(normalArray_normalized) {

  // Audio files with two channels are interleaved, meaning that [channel0_datapoint0, channel1_datapoint0, channel0_datapoint1, channel1_datapoint1, ...channel0_datapointn-1, channel1_datapointn-1] 
  var channel1 = [];
	var channel2 = normalArray_normalized.map((val, ind) => {
		if (ind % 2 == 0) {
			channel1.push(val);
			return '';
		} else {
			return val;
		}
	});
	const NonEmptyVals_toKeep = (x) => x.length != 0;
	channel2 = channel2.filter(NonEmptyVals_toKeep);
  
  return [channel1, channel2];
}

// -------------------------------------------------

async function decodeAudioData_from_binaryString_to_uint8Array(binaryString) {
	
	// -----------------------------------------------
	// Decode the binaryString response
	// -----------------------------------------------
	var character_array = binaryString.split('');
	console.log("character_array: ", character_array);
	// Array(38190) [ "�", "�", "�", "d", "\u0000", "\u0000", "\u0000", "\u0000", "\u0000", "\u0000", … ]
			
	// Map each [binary string character; a subset of binary string characters is UTF-8] as an [ASCII number; a number from 0 to number_of_characters]
	var byteArray = character_array.map((character) => { return character.charCodeAt(0); });
	console.log("byteArray: ", byteArray);
	// byteArray:  Array(38190) [ 65533, 65533, 65533, 100, 0, 0, 0, 0, 0, 0, … ]

	// The importance of this mapping is to limit the array values from 0 to 255.
	var uint8Array = new Uint8Array(byteArray);
	console.log('uint8Array: ', uint8Array);
	// uint8Array:  Uint8Array(38190) [ 253, 253, 253, 100, 0, 0, 0, 0, 0, 0, … ]

	// In some ways a uint8Array is an arrayBuffer because the size is "fixed" meaning that no more data will be appended to the array after the UTF-8 characters. And, it is a "fixed" array because the values of the array are limited to a certain range of numbers, from 0 to 255. 

	// Convert UTF-8 array [non-fixed length array] to a binary arrayBuffer [fixed-length array]
	const arrayBuffer = uint8Array.buffer;
	console.log('arrayBuffer: ', arrayBuffer);

	// Determine the length of the typedArray_arrayBuffer
	console.log('arrayBuffer.byteLength: ', arrayBuffer.byteLength);
	
	// --------------------
	
	// Convert the TypedArray into a normal array
	const normalArray = await Array.from(uint8Array);
	console.log('normalArray: ', normalArray);

	// Determine the length of the normalArray.length
	console.log('normalArray.length: ', normalArray.length);

	var arr_char = await obtain_array_characteristics(normalArray);
	console.log('arr_char: ', arr_char);

	// --------------------

	// Normalize the audio data in arrayBuffer from [-1, 1]
	// var normalArray_normalized = await normalArray.map((val, ind) => { return val/arr_char.max_amp; });  // gave wrong results
	// var normalArray_normalized = await normalArray.map((val, ind) => { return val/99; });  // gave wrong results
	// console.log('normalArray max min: ', [normalArray_normalized.sort().shift(), normalArray_normalized.sort().pop()])
	// RESULT: it gives a value from 0 to 2.5656... not exactly what was expected
	
	// OR

	// Try with Tensorflow library
	const tf_normalArray = tf.tensor1d(normalArray);
	const max_amp = tf.scalar(arr_char.max_amp);
	var normalArray_normalized_tf = await tf_normalArray.div(max_amp);
	  
	// --------------------
	
	// Convert Tensorflow_array to Array
	const normalArray_normalized = normalArray_normalized_tf.arraySync();
	console.log('normalArray max min: ', [normalArray_normalized.sort().shift(), normalArray_normalized.sort().pop()])
	  
	// --------------------
	
	// Only for verification
	var arr_char_normalized = await obtain_array_characteristics(normalArray_normalized);
	console.log('arr_char_normalized: ', arr_char_normalized);
	
	// --------------------

	return normalArray_normalized;
}

// -----------------------------------------------

async function obtain_array_characteristics(arr) {

	var arr_char = {};
	
	arr_char.mu = await mean(arr);
	arr_char.sigma = await std(arr);

	const arr_sort = arr.sort();
	arr_char.max_val = arr_sort.at(arr.length-1);
	arr_char.min_val = arr_sort.at(0);

	// Maximum amplitude
	arr_char.max_amp = [Math.abs(arr_char.min_val), arr_char.max_val].sort().pop();
	
	return arr_char;
}
	
// -----------------------------------------------

async function sum(arr) {
	return arr.reduce((accumulator, currentValue) => accumulator + currentValue, 0);
}

// -----------------------------------------------
  
async function mean(arr) {
	return await sum(arr)/arr.length;
}

// -----------------------------------------------

async function std(arr) {
	const mu =  await mean(arr);
	// console.log('mu: ', mu);

	var arr1 = arr.map((x) => { return x-mu; });
	const summ = await sum(arr1);
	// console.log('summ: ', summ);

	const out = Math.sqrt( Math.pow(summ, 2)/arr.length );
	// console.log('out: ', out);
	
	return out;
}
  
// -------------------------------------------------


	


</script>
</body>
</html>
